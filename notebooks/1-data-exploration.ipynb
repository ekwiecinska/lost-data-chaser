{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import data_chaser as dc\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from data_chaser.plot.plotly import missing_value_heatmap, missing_data_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will define the data directory. I recommend `lost-data-chaser/data` such that you can follow along with the notebook. The datasets we will use first are all .csv files from:\n",
    "- [Meteorite landings](https://catalog.data.gov/dataset/meteorite-landings)\n",
    "- [Near Earth Comets](https://catalog.data.gov/dataset/near-earth-comets-orbital-elements)\n",
    "- [Fire and Bolide Reports](https://catalog.data.gov/dataset/fireball-and-bolide-reports)\n",
    "- [Global Landslide Catalog](https://catalog.data.gov/dataset/global-landslide-catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "fnames = sorted([os.path.join(datadir, fname) for fname in os.listdir(datadir)])\n",
    "print(fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the filenames, let's load the data in and inspect the head to get a feeling of the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_df = pd.read_csv(fnames[0])\n",
    "fire_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landslide_df = pd.read_csv(fnames[1])\n",
    "landslide_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor_df = pd.read_csv(fnames[1])\n",
    "meteor_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_df = pd.read_csv(fnames[3])\n",
    "comet_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the `NaN` distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location of NaNs in each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start implementing a solution, it is important for us to visualise the distribution of missing values (or `NaNs`) for each dataset. This way, we can better understand the sparsity of the data that we're dealing with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = missing_value_heatmap(fire_df, \"fire_df\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = missing_value_heatmap(meteor_df, \"meteor_df\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = missing_value_heatmap(landslide_df, \"landslide_df\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = missing_value_heatmap(comet_df, \"comet_df\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots, we can see there are generally 4 types of missing data challenges that we must consider: \n",
    "1. Columns with **complete** sparsity (no values)\n",
    "2. Columns with **high** sparsity (around 90% of values are missing)\n",
    "3. Columns with **low/medium sparsity** (50% or higher values are present)\n",
    "4. Completely sparsity (few values in most columns). This type isn't present in these datasets but we can experiment with engineering some.\n",
    "\n",
    "We must also consider dependencies (or lack of) in the data. Some columns may be measuring samples (rows) with some temporal dependence on each other, e,g a time series from the same signal. Others may be measuring **independent** events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratio of missing data to present data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_fig = missing_data_ratios([comet_df, meteor_df, landslide_df, fire_df], ['comet_df', 'meteor_df', 'landslide_df', 'fire_df'])\n",
    "ratio_fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (data_chaser)",
   "language": "python",
   "name": "data_chaser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
